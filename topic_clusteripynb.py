# -*- coding: utf-8 -*-
"""Topic_Clusteripynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1thPll7kzfyf7UCqRnxBi2K1Pwje049rz
"""

pip install sentence-transformers umap-learn hdbscan matplotlib

pip install bertopic

from sentence_transformers import SentenceTransformer
import pandas as pd
import umap
import hdbscan
from bertopic import BERTopic
import matplotlib.pyplot as plt
from tqdm import tqdm

# Load SBERT model
model = SentenceTransformer('all-MiniLM-L6-v2')

# Load your dataset
df = pd.read_csv('/content/cleaned_utterances.csv')  # Replace with your file path
utterances = df['Utterances'].tolist()  # Replace 'UtteranceColumn' with your column name

# Generate embeddings
embeddings = model.encode(utterances, show_progress_bar=True)

# Dimensionality reduction with UMAP
umap_model = umap.UMAP(n_neighbors=15, n_components=5, metric='cosine')
umap_embeddings = umap_model.fit_transform(embeddings)

# Clustering with HDBSCAN
hdbscan_model = hdbscan.HDBSCAN(min_cluster_size=15, metric='euclidean', cluster_selection_method='eom')

# Create a topic model with a minimum topic size of 50
topic_model = BERTopic(umap_model=umap_model,
                       hdbscan_model=hdbscan_model,
                       min_topic_size=50)
topics, _ = topic_model.fit_transform(utterances)

# Visualize top words in each cluster with a progress bar
for topic in tqdm(set(topics), desc="Plotting Topics"):
    if topic != -1:  # Ignore the outlier cluster
        plt.figure(figsize=(10, 4))
        topic_words = topic_model.get_topic(topic)
        if topic_words:  # Check if topic_words is not empty
            words = [word for word, _ in topic_words[:7]]
            scores = [score for _, score in topic_words[:7]]
            plt.barh(words, scores)
            plt.gca().invert_yaxis()
            plt.title(f"Cluster {topic}")
            plt.show()